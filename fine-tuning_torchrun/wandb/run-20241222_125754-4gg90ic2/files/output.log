è®­ç»ƒé›†åŠ è½½å®Œæˆï¼Œå…±æœ‰ 32000 ä¸ªæ ·æœ¬ã€‚
éªŒè¯é›†åŠ è½½å®Œæˆï¼Œå…±æœ‰ 4000 ä¸ªæ ·æœ¬ã€‚
æ•°æ®é¢„å¤„ç†å®Œæˆã€‚
/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/mnt/file2/changye/NLPFINAL/fine-tuning/trainer.py:109: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
  0%|                                                                                                                               | 0/6000 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.
  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                        | 569/6000 [35:27<5:17:13,  3.50s/it]
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 3e-05, 'epoch': 0.0}
{'loss': 0.0134, 'grad_norm': nan, 'learning_rate': 3e-05, 'epoch': 0.05}
                                                                                                                                                             
{'eval_loss': nan, 'eval_runtime': 26.6995, 'eval_samples_per_second': 149.816, 'eval_steps_per_second': 9.363, 'epoch': 0.05}
{'loss': 0.0107, 'grad_norm': nan, 'learning_rate': 3e-05, 'epoch': 0.1}
{'eval_loss': nan, 'eval_runtime': 27.5752, 'eval_samples_per_second': 145.058, 'eval_steps_per_second': 9.066, 'epoch': 0.1}
{'loss': 0.0062, 'grad_norm': nan, 'learning_rate': 3e-05, 'epoch': 0.15}
{'eval_loss': nan, 'eval_runtime': 28.2121, 'eval_samples_per_second': 141.783, 'eval_steps_per_second': 8.861, 'epoch': 0.15}
{'loss': 0.0131, 'grad_norm': nan, 'learning_rate': 3e-05, 'epoch': 0.2}
{'eval_loss': nan, 'eval_runtime': 26.4709, 'eval_samples_per_second': 151.109, 'eval_steps_per_second': 9.444, 'epoch': 0.2}
{'loss': 0.0107, 'grad_norm': nan, 'learning_rate': 3e-05, 'epoch': 0.25}
{'eval_loss': nan, 'eval_runtime': 28.4322, 'eval_samples_per_second': 140.686, 'eval_steps_per_second': 8.793, 'epoch': 0.25}
