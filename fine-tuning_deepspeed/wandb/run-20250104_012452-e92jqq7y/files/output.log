[2025-01-04 01:24:53,748] [INFO] [comm.py:652:init_distributed] cdb=None
Loading checkpoint shards:  33%|████████████████████████████                                                        | 1/3 [00:10<00:21, 10.78s/it]
[rank6]: Traceback (most recent call last):
[rank6]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/train.py", line 142, in <module>
[rank6]:     main()
[rank6]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/train.py", line 60, in main
[rank6]:     model, tokenizer, model_type = load_model_and_tokenizer(args.model_path, args.local_rank)
[rank6]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/model.py", line 44, in load_model_and_tokenizer
[rank6]:     model=AutoModelForCausalLM.from_pretrained(
[rank6]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
[rank6]:     return model_class.from_pretrained(
[rank6]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4264, in from_pretrained
[rank6]:     ) = cls._load_pretrained_model(
[rank6]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4777, in _load_pretrained_model
[rank6]:     new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
[rank6]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/modeling_utils.py", line 871, in _load_state_dict_into_meta_model
[rank6]:     if dtype is not None and torch.is_floating_point(param) and not is_param_float8_e4m3fn:
[rank6]: KeyboardInterrupt
[rank6]: Traceback (most recent call last):
[rank6]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/train.py", line 142, in <module>
[rank6]:     main()
[rank6]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/train.py", line 60, in main
[rank6]:     model, tokenizer, model_type = load_model_and_tokenizer(args.model_path, args.local_rank)
[rank6]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/model.py", line 44, in load_model_and_tokenizer
[rank6]:     model=AutoModelForCausalLM.from_pretrained(
[rank6]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
[rank6]:     return model_class.from_pretrained(
[rank6]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4264, in from_pretrained
[rank6]:     ) = cls._load_pretrained_model(
[rank6]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4777, in _load_pretrained_model
[rank6]:     new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
[rank6]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/modeling_utils.py", line 871, in _load_state_dict_into_meta_model
[rank6]:     if dtype is not None and torch.is_floating_point(param) and not is_param_float8_e4m3fn:
[rank6]: KeyboardInterrupt
