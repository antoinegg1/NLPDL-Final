[2025-01-04 01:34:20,739] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-01-04 01:34:20,739] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-01-04 01:34:23,157] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 1, num_elems = 0.13B
[rank0]: Traceback (most recent call last):
[rank0]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/train.py", line 142, in <module>
[rank0]:     main()
[rank0]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/train.py", line 60, in main
[rank0]:     model, tokenizer, model_type = load_model_and_tokenizer(args.model_path, args.local_rank)
[rank0]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/model.py", line 40, in load_model_and_tokenizer
[rank0]:     model, model_type = _load_model(model_name)
[rank0]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/model.py", line 76, in _load_model
[rank0]:     model = AutoModelForCausalLM.from_pretrained(
[rank0]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
[rank0]:     return model_class.from_pretrained(
[rank0]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4130, in from_pretrained
[rank0]:     model = cls(config, *model_args, **model_kwargs)
[rank0]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 511, in wrapper
[rank0]:     f(module, *args, **kwargs)
[rank0]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py", line 990, in __init__
[rank0]:     self.model = MistralModel(config)
[rank0]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 511, in wrapper
[rank0]:     f(module, *args, **kwargs)
[rank0]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py", line 693, in __init__
[rank0]:     self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size, self.padding_idx)
[rank0]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 521, in wrapper
[rank0]:     self._post_init_method(module)
[rank0]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1087, in _post_init_method
[rank0]:     param.data = param.data.to(self.local_device)
[rank0]: NotImplementedError: Cannot copy out of meta tensor; no data!
[rank0]: Traceback (most recent call last):
[rank0]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/train.py", line 142, in <module>
[rank0]:     main()
[rank0]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/train.py", line 60, in main
[rank0]:     model, tokenizer, model_type = load_model_and_tokenizer(args.model_path, args.local_rank)
[rank0]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/model.py", line 40, in load_model_and_tokenizer
[rank0]:     model, model_type = _load_model(model_name)
[rank0]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/model.py", line 76, in _load_model
[rank0]:     model = AutoModelForCausalLM.from_pretrained(
[rank0]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
[rank0]:     return model_class.from_pretrained(
[rank0]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4130, in from_pretrained
[rank0]:     model = cls(config, *model_args, **model_kwargs)
[rank0]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 511, in wrapper
[rank0]:     f(module, *args, **kwargs)
[rank0]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py", line 990, in __init__
[rank0]:     self.model = MistralModel(config)
[rank0]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 511, in wrapper
[rank0]:     f(module, *args, **kwargs)
[rank0]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py", line 693, in __init__
[rank0]:     self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size, self.padding_idx)
[rank0]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 521, in wrapper
[rank0]:     self._post_init_method(module)
[rank0]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1087, in _post_init_method
[rank0]:     param.data = param.data.to(self.local_device)
[rank0]: NotImplementedError: Cannot copy out of meta tensor; no data!
