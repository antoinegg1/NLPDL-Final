[2025-01-04 01:24:53,585] [INFO] [comm.py:652:init_distributed] cdb=None
Loading checkpoint shards:  33%|████████████████████████████                                                        | 1/3 [00:11<00:23, 11.56s/it]
[rank5]: Traceback (most recent call last):
[rank5]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/train.py", line 142, in <module>
[rank5]:     main()
[rank5]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/train.py", line 60, in main
[rank5]:     model, tokenizer, model_type = load_model_and_tokenizer(args.model_path, args.local_rank)
[rank5]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/model.py", line 44, in load_model_and_tokenizer
[rank5]:     model=AutoModelForCausalLM.from_pretrained(
[rank5]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
[rank5]:     return model_class.from_pretrained(
[rank5]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4264, in from_pretrained
[rank5]:     ) = cls._load_pretrained_model(
[rank5]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4777, in _load_pretrained_model
[rank5]:     new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
[rank5]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/modeling_utils.py", line 871, in _load_state_dict_into_meta_model
[rank5]:     if dtype is not None and torch.is_floating_point(param) and not is_param_float8_e4m3fn:
[rank5]: KeyboardInterrupt
[rank5]: Traceback (most recent call last):
[rank5]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/train.py", line 142, in <module>
[rank5]:     main()
[rank5]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/train.py", line 60, in main
[rank5]:     model, tokenizer, model_type = load_model_and_tokenizer(args.model_path, args.local_rank)
[rank5]:   File "/mnt/file2/changye/NLPFINAL/fine-tuning_deepspeed/model.py", line 44, in load_model_and_tokenizer
[rank5]:     model=AutoModelForCausalLM.from_pretrained(
[rank5]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
[rank5]:     return model_class.from_pretrained(
[rank5]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4264, in from_pretrained
[rank5]:     ) = cls._load_pretrained_model(
[rank5]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4777, in _load_pretrained_model
[rank5]:     new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
[rank5]:   File "/home/changye/miniconda3/envs/ML/lib/python3.10/site-packages/transformers/modeling_utils.py", line 871, in _load_state_dict_into_meta_model
[rank5]:     if dtype is not None and torch.is_floating_point(param) and not is_param_float8_e4m3fn:
[rank5]: KeyboardInterrupt
