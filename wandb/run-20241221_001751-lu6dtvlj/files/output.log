You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Using 8 GPUs!
Epoch 1/3:   0%|                                                                                                    | 0/1810 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.
/home/changye/miniconda3/envs/sae/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
Epoch 1/3: 100%|███████████████████████████████████████████████████████████████████████████| 1810/1810 [2:18:16<00:00,  4.58s/it, loss=0.044]
Saved checkpoint at step 500
Saved checkpoint at step 1000
Saved checkpoint at step 1500
Validation 1/3:   0%|                                                                                                | 0/227 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "/mnt/file2/changye/NLPFINAL/pre-train.py", line 193, in <module>
    main()
  File "/mnt/file2/changye/NLPFINAL/pre-train.py", line 175, in main
    val_loss += loss.item()
RuntimeError: a Tensor with 8 elements cannot be converted to Scalar
Traceback (most recent call last):
  File "/mnt/file2/changye/NLPFINAL/pre-train.py", line 193, in <module>
    main()
  File "/mnt/file2/changye/NLPFINAL/pre-train.py", line 175, in main
    val_loss += loss.item()
RuntimeError: a Tensor with 8 elements cannot be converted to Scalar
